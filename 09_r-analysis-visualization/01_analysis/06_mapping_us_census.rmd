---
title: "Mapping_Basics"
author: "Julia Christensen"
date: "March 11, 2019"
output: html_document
---

****************************************************
# 1) Set up

## 1.1. General Set Up
```{r}
### Clear global environment
rm(list=ls()) 

### Cache all chunks 
knitr::opts_chunk$set(cache = TRUE)
```

Note: Set cache=TRUE if your file takes a long time to knit -- "when evaluating code chunks, the cached chunks are skipped, but the objects created in these chunks are (lazy-) loaded from previously saved databases (.rdb and .rdx) files, and these files are saved when a chunk is evaluated for the first time, or when cached files are not found (e.g. you may have removed them by hand)" (source: https://yihui.org/knitr/options/#cache). 

## 1.2. Libraries 
```{r}
# Unload all packages 
library(pacman)
pacman::p_unload(all)

### Download Libraries 
library(pacman)
p_load(tidyverse, data.table, rmarkdown, knitr, tinytex, magrittr,
       gplots, #for heatmaps
       viridis, RColorBrewer, scales, #good colors
       # grDevices, graphics,
       # mapproj, ggmap,
       rgdal, #used to read shapefile
       # tmap, 
       # maptools, tmaptools,
       tidycensus, censusapi #two different census api packages
       )
```

Note: Not all of these packages are used in this file. In general, it's not a good idea to have a bunch of extra packages (sometimes two packages have a function with the same name, which causes chaos). However, I don't remember which ones are necessary... 

## 1.3. Census API
```{r}
### First, go to the 06_setup folder and 

### Open API key (census_api_key)
source("../06_setup/api_key.R")

### Store API Key (for tidycensus package)
tidycensus::census_api_key(key = census_api_key, 
                           overwrite = TRUE, 
                           install = FALSE)
```

Notes: 

* Get API Key here: https://api.census.gov/data/key_signup.html
* PLEASE DO NOT use my API key regularly or circulate these files without deleting my key. For teaching purposes, I have left it in here. 

## 1.4. Visualization set up  

Notice how most Anscombe's quartet do not have gridlines. 

```{r}
# Change default plot dimensions
knitr::opts_chunk$set(fig.width=8, fig.height=5)
```


****************************************************
# 2) Get Shapefile (sp) Data

## 2.1. Types of data

There are two basic types of spatial: *vector* and *raster*. 

* Vector data include points, lines, and polygons-the things generally contained in files called shapefiles. 
* Raster data are comprised of single raster layers and raster stacks (stacks of raster layers) and are essentially images-values mapped to a grid. We will use the tidycensus package later to download raster data. 

## 2.2. What is a shapefile?

You will generally encounter *vector* data as shapefiles (extension .shp). However, you will also encounter vectors as datasets of points that include the coordinates of observations and some information about those points (often  .csv). At their core, all vector files are simply collections of points. For points-based files, this statement is obvious. Lines and polygons are collections of points, so again, we see that the classes of objects that make up vectors are "simply" collections of points.

## 2.3. Download Shapefile 

Let's load a shapefile. Specifically, we will load the polygons from the US Census.
```{r}
# Download USDA shapefile
setwd("../02_data/data-raw/Shapefile/")
US_counties <- rgdal::readOGR(dsn=".",layer="gz_2010_us_050_00_5m",
                              stringsAsFactors=FALSE)
```

Specifically, This is the 2010 Census shapefile. Other Shapefiles can be found here: https://www.census.gov/geo/maps-data/data/cbf/cbf_counties.html.

## 2.4. Exploring Shapefile 
Now, let's check a few things-the class of the object we just read into R, its dimensions, and plotting it.
```{r}
class(US_counties)
dim(US_counties)
plot(US_counties)
```

Cool, right? So what does it mean that this "spatial polygons data frame" has dimensions 3221 and 6? The first number is generally the number of distinct shapes (features) in the shapefile. In our case, we 3221 polygons. And what about the second number? The second number gives us the number of fields-essentially the number of variables (a.k.a. features) for which we have information for each polygon.

We can dive a bit deeper into the data that compose a shapefile in R. Up to this point, you've seen that you can access the columns of a data.frame4 using the dollar sign, e.g., pretend_df$variable1. Spatial data frames add an additional level-we now have slots. You can still find out the names of the fields (variables) using names(US_counties), but now you can also find the names of the slots using slotNames(US_counties):
```{r}
names(US_counties)
slotNames(US_counties)
```

The data slot is a data frame like we've seen before, but now there are other slots related to our spatial data: the polygons, the plot order (plotOrder), the bounding box (bbox), and the proj4string (a string that encodes the projection used for the polygons' coordinates).

**Sidenote:** the `@` operator is used with shapefiles instead of `$` to extract particular elements from object. In addition, elements of the shapefile object are called *slots* and accessed using `@`. 

Let's take a look at the data slot. To access the slots, use the slot's name in conjunction with an ampersat, e.g., `US_counties@data`. 
```{r}
# Note that the data slot contents are a data frame with 6 variables and 3221 rows
US_counties@data %>% str()

# Preview data slot 
US_counties@data %>% head()
```

Most of the other slots aren't particularly interesting. 

However, the polygons slot is (1) a huge list, and (2) important. 
```{r}
# Polygons slot is a list of length 3221
US_counties@polygons %>% class()
US_counties@polygons %>% length()

# Polygons slot contains longitude and latitude points for every geographic unit 
US_counties@polygons[[1]]@Polygons[[1]]@coords %>% head()
```

## 2.5. Extract @data and @polygons data from shapefile 

Eventually, we want a list of points (lat and long) and variables that tell us what geographic unit each point belongs in. Then we will merge in the fill data (e.g. Census demographics) based on the geographic units. 

Above we showed that... 

* `@data` contains the geographic unit names and ids 
* `@polygons` contains the lat and long points 

Note that the only shared id variable across these two datasets is unique to the shapefile. We can't use a generic id like FIPS codes (the standard US county code) to connect the data we want to map and the map coordinates until we add generic id's like FIPS or county names (which are in `@data`) to the list of coordinates in `@polygons`.

### 2.5.1. Step 1: Save tidied shapefile with lat-long and shapefile id  
```{r, message = FALSE, warning = FALSE}
# Create map dataframe
lat_long_coords <- data.table(broom::tidy(US_counties)) 

# Look at map dataframe (Note: no FIPS column)
lat_long_coords %>% head()
```

Note(s):

* In general, it's bad practice to turn off warnings for a chunk, but I've done so here because printing the warnings makes R take (a lot) longer. This warning is only about coercing factors and characters. 
* For chunk options, see https://rmarkdown.rstudio.com/lesson-3.html
* FIPS codes are a common way to identify US counties and merge county-level data across datasets

### 2.5.2. Crosswalk for shapefile id and FIPS 
```{r}
# Save data in data slot
geo_names <- US_counties@data

# Save row IDs in a column 
geo_names <- cbind(id=rownames(geo_names),geo_names)

# Standardize county id (FIPS as 5 digit code)
geo_names %<>% as_tibble() %>%
  mutate(FIPS = as.character(paste0(STATE,COUNTY)))
```

Note(s):

* Note that sometimes state and county FIPS codes are stored in seperate columns. I usually create a standardized version of them. Here I have saved the code as a 5 digit character variable. You could save it as a numeric vector, especially if your computer is acting slow. Just make sure to make the variable the same data type in all datasets matched with the shape file. 

## 2.6. Summary of Shapefile prep

The code chunk below contains all the code necessary to use the shapefile. Everything else is exploratory. Thus, if you want to make your own plot using the sp 

```{r, message = FALSE, warning = FALSE}
# Step 1: Download USDA shapefile
setwd("../02_data/data-raw/Shapefile/")
US_counties <- rgdal::readOGR(dsn=".",layer="gz_2010_us_050_00_5m",
                              stringsAsFactors=FALSE)

# Step 2: isolate lat-long coordinates and shapefile IDs
lat_long_coords <- data.table(broom::tidy(US_counties)) 

# Step 3: isolategeography names, stardard ID vars like FIPS, and shapefile IDs
geo_names <- 
  # Subset dataset with geo names 
  US_counties@data %>% 
  # Add shapefile IDs (stored as rownames)
  bind_cols(id=as.character(rownames(US_counties@data))
            ) %>% 
  # Verify datatype
  as_tibble() %>%
  # Verify class of FIPS variable 
  mutate(FIPS = as.character(paste0(STATE,COUNTY)))

# (Optional) Step 4: Verify 'id' is not a factor in either dataset
class(lat_long_coords$id)
class(geo_names$id)

# (Optional) Step 5: Combine into one crosswalk using 'id'
crosswalk <- 
  left_join(x = lat_long_coords, #keep all 
            y = geo_names, #add geo names where ids match
            by = "id" #match using id variable
            )
```

## 2.7. Other geographic data 

### 2.7.1. County and State Borders

ggplot2 has built-in datasets with the lat-long coordinates for state and county borders. For clarity, we can save these as new objects. 

```{r}
# Save county and state borders as seperate objects
map_county <- ggplot2::map_data("county")
map_state <- ggplot2::map_data("state")

map_state %>% head()
```

### 2.7.2. State data

This base R dataset called `state` might not get used anywhere in this dataset, but this base R dataset is useful when converting state name variables and matching between datasets with different state name formatting or abbreviations. 

```{r}
data(state)
```


****************************************************
# 3) Get Census Data

## 3.1. Select variables to download 
```{r}
# Select Variables (look on census website for variable codes)
racevars <- c(White = "P005003", 
              Black = "P005004", 
              Asian = "P005006", 
              Hispanic = "P004003")
```



## 3.2. Download Census Data
```{r}
# Use tidycensus
race_data_raw <- 
  # Download decennial census data
    tidycensus::get_decennial(geography = "county", 
                              variables = c(racevars),
                              summary_var = "P001001", #total pop
                              geometry=FALSE, 
                              year=2010 #select census year
                              ) %>%
  # Standardize name and class of id variable 
    mutate(FIPS = as.character(GEOID))
```

Note(s):

*Use get_acs() to get american community survey data 
*Can select different geographic units: https://www2.census.gov/geo/pdfs/reference/geodiagram.pdf. See also https://walkerke.github.io/tidycensus/articles/basic-usage.html.
*P001001 is the total population variable from the census: https://www.socialexplorer.com/data/C2000/metadata/?ds=SF1&var=P001001.
*The "geometry" option allows you to download a shapefile with the census data. In my experience, this is very slow, but see https://knaaptime.com/projects/neighborhood-types/opportunity-types-in-r/ for an example. 

```{r}
# Save raw data
write_csv(race_data_raw, path="../02_data/data-raw/census_race_2010.csv")
```

```{r, eval=F}
# Load raw data if necessary 
race_data_raw <- read_csv(path="../02_data/data-raw/wb-census_race_2010.csv")
```


## 3.3. Clean Census data 
```{r}
# Convert to wide data 
race_data <- race_data_raw %>% 
    spread(key = variable, value = value)

# Add variables     
race_data %<>%   
  # Create new categories 
    dplyr::mutate(non_white = Asian + Black + Hispanic) %>% 
    dplyr::mutate(black_hispanic = Black + Hispanic) %>%
  # Calc pop by race as a % of total pop
    dplyr::mutate_at(vars(Asian:black_hispanic),
                     .funs=funs(pct=./summary_value))

# Rename NAME 
race_data %<>% rename(cty_name_census=NAME)

# Look at new dataset
race_data %>% glimpse()
```


****************************************************
# 4) Combine Census and Shapefile Data

The code in this section should work for any county-level census variables, but it may need to be updated if you use a different shapefile or match based on a different geography. 

If you use a different geography or part of the world, you would need to merge it with the shapefile differently or (if you are mapping the US) use the tidycensus download geometry option. 

Make sure to look closely at the final dataset that we use to generate maps (`map_df_usa`). Ultimately, you always want to have two columns of lat-long points and columns with the data that you want to plot (e.g. racial demographics). 

## 4.1. Use crosswalk(s) to merge race data with geography

### 4.1.1. Option 1: single step process
```{r}
# Merge race data with crosswalk from section 2.6
map_df <- left_join(x = crosswalk, 
                    y = race_data, 
                    by = "FIPS")


```

### 4.1.1. Option 2: two step process
```{r}
# Merge race data with shapefile IDs
race_data_wID <- left_join(x = geo_names, 
                           y = race_data, 
                           by = "FIPS")

# Merge census data with lat-long dataframe 
map_df_s2 <- left_join(x = lat_long_coords, 
                       y = race_data_wID, 
                       by = "id")
```

### 4.1.3. Check options
```{r}
# Check if all cells in datasets are the same (total different)
(map_df!=map_df_s2) %>% as_tibble() %>% summarise_all(sum) %>% t()
```

# 4.2. Subset to mainland USA

Our shapefile contains the real-world location of each US state and territory. Thus, areas outside mainland USA do not look good when plotted. Try commenting out the filter() function and see what happens (aka run `map_df_usa <- map_df` instead of the chunk below). 

```{r}
# Leave out AK, HI, and PR (state FIPS: 02, 15, and 72)
map_df_usa <- map_df %>%
  filter(!STATE %in% c("02","15","72"))
```


****************************************************
# 5) Generate Maps (sp)

## 5.1. Basic map
```{r}
# Generate default map 
map_df_usa %>%
    ggplot() + 
      geom_polygon(aes(long, lat, group = group, fill = Black_pct)) +
      theme_void()
```

## 5.2. Add formatting
```{r}
# Generate map 
map_df_usa %>%
  ggplot() + 
    # Plot data for each county  
      geom_polygon(aes(long, lat, group = group, fill = Black_pct),
                   color = NA, size = 0.1) +
    # Plot state borders (use data=map_county for county borders)
      geom_polygon(data = map_state, aes(long, lat, group = group),
                   fill = NA, color = "white") +
    # Titles / labels 
      labs(title="Black Population, 2010 Census", x=NULL, y=NULL) +
    # Theme 
      theme_void() +
      theme(text = element_text(size=13),
            strip.text.x = element_text(size = 14)) + #increase font size
    # Fill colors 
      scale_fill_distiller(palette = "BrBG",
                           trans=log2_trans(), #Log transformation of scale
                           name = "Key:", 
                           labels = scales::percent #Change label format
                           )

```

## 5.3. Save map
```{r}
# Save map 
ggsave("../03_plots/map_race_census2010.pdf", #plot name
       plot = last_plot(), #save last plot outputted 
       width=8, height=6, units="in" #dimensions of saved plot
       ) 
```

## 5.4. Multi-map plot
```{r}
# Generate map 
map_df_usa %>%
  # Select variables to be plotted 
    select(lat, long, group, Asian_pct:White_pct) %>%
  # Rename variables 
    rename("Asian"="Asian_pct",
           "Black"="Black_pct",
           "Hispanic"="Hispanic_pct",
           "White"="White_pct") %>%
  # Gather/stack variables 
    gather(key="race",value="pct", -lat, -long, -group) %>%
  # Plot map 
    ggplot() + 
      # Plot data for each county  
        geom_polygon(aes(long, lat, group = group, fill = pct),
                     color = NA, size = 0.1) +
      # Plot state borders (use data=map_county for county borders)
        geom_polygon(data = map_state, aes(long, lat, group = group),
                     fill = NA, color = "white") +
      # Create seperate plots for each race category
        facet_wrap(~race, ncol = 2) +
      # Titles / labels 
        labs(title="2010 Census", x=NULL, y=NULL) +
      # Theme 
        theme_void() +
        theme(text = element_text(size=13),
              strip.text.x = element_text(size = 14)) + 
      # Fill colors 
        scale_fill_distiller(palette = "BrBG",
                             trans=log2_trans(), #Log transformation of scale
                             name = "Key:", 
                             labels = scales::percent #Change label format
                             )

# Save map 
ggsave("../03_plots/map_race_census2010_2x2.pdf", #plot name
       plot = last_plot(), #save last plot outputted 
       width=8, height=6, units="in" #dimensions of saved plot
       ) 
```

## 5.5. Functionalize single-variable plot 

### 5.5.1. Write Function 
```{r}
map_race_fun <- function(dat, #dataset 
                         fill_var, #name of variable to plot 
                         txt_var, #text to use in title of variable (i.e. 'Black', 'White')
                         log_scale=TRUE #use log for raster data
                         )
{
  # Make sure that the border dataset is available in the function 
    map_state <- map_data("state")
  
  # Generate and save map as variable 
    rm <- 
      ggplot(dat, aes(x=long, y=lat, group=group)) +
        # Plot data for each county (based on fill_var)
          geom_polygon(aes_string(fill = fill_var)) +
        # Plot state borders (use data=map_county for county borders)
          geom_path(data = map_state, colour = "white", size=.1) +
        # See note below (related to how 2D map created for 3D globe)
          coord_quickmap() +
        # Titles / labels (based on txt_var)  
          labs(title=paste0("% ",txt_var," by County (2010 Census)"), x="", y="") +
        # Theme 
          theme_void() 
    
  # Fill colors & scale options 
    if(log_scale==TRUE){
      rm <- rm +
        scale_fill_viridis(alpha = .75, begin = 0, end = 1, 
                           direction = -1, discrete = FALSE, option = "C",
                           trans=log10_trans(),
                           name = "Key:",
                           labels = scales::percent)  
    } else{
      rm <- rm +
        scale_fill_viridis(alpha = .75, begin = 0, end = 1, 
                           direction = -1, discrete = FALSE, option = "C",
                           name = "Key:",
                           labels = scales::percent) 
    }
  
  # Save map (uses fill_var)
    ggsave(paste0("../03_plots/map_race_",fill_var,"_census2010.pdf"), 
         plot = rm, width=8, height=6, units="in") 
  
  # Print map to R output 
    rm
}
```

Note(s):

* coord_map() projects a portion of the earth, which is approximately spherical, onto a flat 2D plane. coord_quickmap() is a quick approximation that does preserve straight lines. It works best for smaller areas closer to the equator.
* Notice that the white plot above isn't very informative. That's because there are white people pretty much everywhere (at least at a county level), and we scaled the fill colors using a log function. The log_scale option allows us to scale the white map differently. 
* I've saved and then printed the map because it won't print to screen unless it is printed after the ggsave() function. 
* viridis is my favorite color package at the moment. Colorbrewer is also good and has a good website, but prioritizes readability and versitility over beauty.  

### 5.5.1. Run function for each race category  
```{r}
map_df_usa %>% map_race_fun(fill_var = "Black_pct", txt_var = "Black")

map_df_usa %>% map_race_fun(fill_var = "Hispanic_pct", txt_var = "Hispanic")

map_df_usa %>% map_race_fun(fill_var = "Asian_pct", txt_var = "Asian")

map_df_usa %>% map_race_fun(fill_var = "White_pct", txt_var = "White", log_scale=FALSE)
```

Note(s):  Learning how to generate maps or other plots using functions is life changing. Copying and pasting graphs is THE WORST because, inevitably, you will have to mess with the formatting later on. 



****************************************************
# 6) Alternate: sf geometry 

* Above, we have used something called sp objects. The "newer, fancier" way to do mapping in R is to use the sf() package instead. In my experience, sf() is still very slow. 
* tidyverse page for geom_sf(): https://ggplot2.tidyverse.org/reference/ggsf.html
* more reference info for sf(): https://cran.r-project.org/web/packages/sf/vignettes/sf1.html

## 6.1. Download and Clean Census Data WITH GEOMETRY
```{r}
# Download decennial census data
race_data_county2 <- 
    tidycensus::get_decennial(geography = "county", 
                              variables = c(racevars),
                              summary_var = "P001001", #total pop
                              geometry=TRUE, 
                              shift_geo=FALSE,
                              year=2010, #select census year
                              output="wide" #return output in wide format instead
                              ) 

# Save raw data
save(race_data_county2, file="../02_data/data-raw/census_race_2010_wgeo.RData")

# Load raw data if necessary 
load(file="../02_data/data-raw/census_race_2010_wgeo.RData")

# Create % versions of variables 
race_data_county2 %<>%
  mutate_at(vars(White, Black, Asian, Hispanic),
            funs(pct = 100 * (. / summary_value)))

# Leave out AK, HI, and PR (state FIPS: 02, 15, and 72)
map_df_usa_2 <- race_data_county2 %>% filter(!str_sub(GEOID,1,2) %in% c("02","15","72"))
```

## 6.2. Cons 

### 6.2.1. Longer to Plot 

Here is the default map using sp. 
```{r}
start.time <- Sys.time() #start clock

# Generate default map using sp
map_df_usa %>%
    ggplot() + 
      geom_polygon(aes(long, lat, group = group, fill = Black_pct)) +
      theme_void()

(Sys.time() - start.time) %>% print() #time elapsed 
```

Here is the default map using sf. 
```{r}
start.time <- Sys.time() #start clock

# Generate default map using sf
map_df_usa_2 %>%
  ggplot(aes(fill = Black_pct, color = Black_pct)) +
  geom_sf() + theme_void()

(Sys.time() - start.time) %>% print() #time elapsed 
```

Note: In the past, downloading data using tidycensus takes a lot longer when "geometry=TRUE". This seems to have gotten a bit better, but the plotting is still slow. 


## 6.3. Benefits

### 6.3.1. Don't have to find a shapefile 

Tidycensus can plot and "return an sf tibble with simple feature geometry in the 'geometry' column. state, county, tract, and block group are supported for 1990 through 2010; block and ZCTA geometry are supported for 2000 and 2010."

### 6.3.2. [US Only] Tidycensus has option of shifting AK and HI
```{r}
# What happens if we try to plot AK and HI normally?
race_data_county2 %>%
  ggplot(aes(fill = Black_pct, color = Black_pct)) +
  geom_sf() + theme_void()

# What happens when we tell tidycensus to shift AK and HI?
  # Download decennial census data
  tidycensus::get_decennial(geography = "county", 
                            variables = c(racevars),
                            summary_var = "P001001", #total pop
                            geometry=TRUE, 
                            shift_geo=TRUE, #(!) 
                            year=2010, #select census year
                            output="wide" #return output in wide format instead
                            ) %>%
    # Convert to %
    mutate_at(vars(White, Black, Asian, Hispanic),
              funs(pct = 100 * (. / summary_value))) %>%
    # Plot 
    ggplot(aes(fill = Black_pct, color = Black_pct)) +
    geom_sf() + theme_void()
```

